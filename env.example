# Copy this file to .env and fill in your values:
#   cp env.example .env

# Optional: port for local server (default: 3000)
# PORT=3000

# Hugging Face API key â€“ required for the AI tab.
# 1. Go to https://huggingface.co/settings/tokens
# 2. Create a "Fine-grained" token (not Classic).
# 3. Under permissions, enable "Inference" or "Inference Providers".
# 4. Paste the token below. (If you get 403, the token needs this permission.)
HUGGINGFACE_API_KEY=your_huggingface_token_here

# Optional: model for router API (default: Qwen/Qwen2.5-7B-Instruct)
# HUGGINGFACE_MODEL=Qwen/Qwen2.5-7B-Instruct

# Optional: model for legacy inference if router returns 403 (default: google/flan-t5-base)
# HUGGINGFACE_LEGACY_MODEL=google/flan-t5-base
